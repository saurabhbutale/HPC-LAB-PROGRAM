{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Basic Command for accessing the CUDA Version and GPU Information\n",
        "####Runtime > Change runtime type > Setting the Hardware accelerator to GPU > Save"
      ],
      "metadata": {
        "id": "-ycIIE8spfuT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ7HeLnRkijK",
        "outputId": "7d6a4ea5-57e9-4065-dfc0-6e93526f4bea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin    cuda\tcuda-12.5\t  etc\t include  libexec     man  sbin   src\n",
            "colab  cuda-12\tdist_metrics.pxd  games  lib\t  LICENSE.md  opt  share\n"
          ]
        }
      ],
      "source": [
        "!ls /usr/local/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!which nvcc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFuDJT66k0oU",
        "outputId": "a2cdc6d1-7c67-4465-aa47-1eedcec17da3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/cuda/bin/nvcc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFDkjJjtlBvm",
        "outputId": "43e333cc-077c-4f46-a84c-83260ff58339"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May  6 04:55:58 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Input"
      ],
      "metadata": {
        "id": "4OZ_ShdF8-9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " #### Matrix Multiplication using CUDA C"
      ],
      "metadata": {
        "id": "vXkkfMmdqF0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_mul.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "#define N 16  // You can increase this to 512 or 1024 for bigger matrices\n",
        "\n",
        "// CUDA Kernel for Matrix Multiplication\n",
        "__global__ void matrixMulKernel(int *A, int *B, int *C, int width) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < width && col < width) {\n",
        "        int sum = 0;\n",
        "        for (int k = 0; k < width; k++) {\n",
        "            sum += A[row * width + k] * B[k * width + col];\n",
        "        }\n",
        "        C[row * width + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "void fillMatrix(int *mat, int width) {\n",
        "    for (int i = 0; i < width * width; i++) {\n",
        "        mat[i] = rand() % 10; // fill with random values 0-9\n",
        "    }\n",
        "}\n",
        "\n",
        "void printMatrix(int *mat, int width) {\n",
        "    for (int i = 0; i < width; i++) {\n",
        "        for (int j = 0; j < width; j++) {\n",
        "            printf(\"%4d \", mat[i * width + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int size = N * N * sizeof(int);\n",
        "\n",
        "    // Allocate memory on host\n",
        "    int *h_A = (int *)malloc(size);\n",
        "    int *h_B = (int *)malloc(size);\n",
        "    int *h_C = (int *)malloc(size);\n",
        "\n",
        "    // Fill host matrices with random values\n",
        "    fillMatrix(h_A, N);\n",
        "    fillMatrix(h_B, N);\n",
        "\n",
        "    // Allocate memory on device\n",
        "    int *d_A, *d_B, *d_C;\n",
        "    cudaMalloc((void **)&d_A, size);\n",
        "    cudaMalloc((void **)&d_B, size);\n",
        "    cudaMalloc((void **)&d_C, size);\n",
        "\n",
        "    // Copy host matrices to device\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define grid and block dimensions\n",
        "    dim3 dimBlock(16, 16);\n",
        "    dim3 dimGrid((N + dimBlock.x - 1) / dimBlock.x,\n",
        "                 (N + dimBlock.y - 1) / dimBlock.y);\n",
        "\n",
        "    // Launch CUDA kernel\n",
        "    matrixMulKernel<<<dimGrid, dimBlock>>>(d_A, d_B, d_C, N);\n",
        "\n",
        "    // Copy result back to host\n",
        "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print results\n",
        "    printf(\"Matrix A:\\n\");\n",
        "    printMatrix(h_A, N);\n",
        "    printf(\"\\nMatrix B:\\n\");\n",
        "    printMatrix(h_B, N);\n",
        "    printf(\"\\nMatrix C (A x B):\\n\");\n",
        "    printMatrix(h_C, N);\n",
        "\n",
        "    // Free memory\n",
        "    free(h_A); free(h_B); free(h_C);\n",
        "    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "032hGQ_sljMD",
        "outputId": "2be253ac-fa4d-4d0f-fd20-0d1d86302a63"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_mul.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 matrix_mul.cu -o matrix_mul"
      ],
      "metadata": {
        "id": "9cBOnKU4o1ic"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./matrix_mul"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3IfR2Boo3xw",
        "outputId": "ab9d9357-4a9c-486a-935d-3aa1fe934491"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix A:\n",
            "   3    6    7    5    3    5    6    2    9    1    2    7    0    9    3    6 \n",
            "   0    6    2    6    1    8    7    9    2    0    2    3    7    5    9    2 \n",
            "   2    8    9    7    3    6    1    2    9    3    1    9    4    7    8    4 \n",
            "   5    0    3    6    1    0    6    3    2    0    6    1    5    5    4    7 \n",
            "   6    5    6    9    3    7    4    5    2    5    4    7    4    4    3    0 \n",
            "   7    8    6    8    8    4    3    1    4    9    2    0    6    8    9    2 \n",
            "   6    6    4    9    5    0    4    8    7    1    7    2    7    2    2    6 \n",
            "   1    0    6    1    5    9    4    9    0    9    1    7    7    1    1    5 \n",
            "   9    7    7    6    7    3    6    5    6    3    9    4    8    1    2    9 \n",
            "   3    9    0    8    8    5    0    9    6    3    8    5    6    1    1    5 \n",
            "   9    8    4    8    1    0    3    0    4    4    4    4    7    6    3    1 \n",
            "   7    5    9    6    2    1    7    8    5    7    4    1    8    5    9    7 \n",
            "   5    3    8    8    3    1    8    9    6    4    3    3    3    8    6    0 \n",
            "   4    8    8    8    9    7    7    6    4    3    0    3    0    9    2    5 \n",
            "   4    0    5    9    4    6    9    2    2    4    7    7    5    4    8    1 \n",
            "   2    8    9    3    6    8    0    2    1    0    5    1    1    0    8    5 \n",
            "\n",
            "Matrix B:\n",
            "   0    6    4    6    2    5    8    6    2    8    4    7    2    4    0    6 \n",
            "   2    9    9    0    8    1    3    1    1    0    3    4    0    3    9    1 \n",
            "   9    6    9    3    3    8    0    5    6    6    4    0    0    4    6    2 \n",
            "   6    7    5    6    9    8    7    2    8    2    9    9    6    0    2    7 \n",
            "   6    1    3    2    1    5    9    9    1    4    9    1    0    7    5    8 \n",
            "   7    0    4    8    0    4    2    9    6    1    0    4    2    2    2    0 \n",
            "   5    5    2    9    0    2    8    3    8    0    4    0    9    1    9    6 \n",
            "   2    5    4    4    9    9    3    6    0    5    0    2    9    4    3    5 \n",
            "   1    7    4    3    1    4    6    9    4    2    2    6    4    1    2    8 \n",
            "   8    9    2    8    8    8    6    8    3    8    3    3    3    8    0    4 \n",
            "   7    6    8    9    0    6    8    7    9    0    3    3    3    7    3    2 \n",
            "   6    5    2    6    5    8    7    9    6    0    4    1    0    4    8    7 \n",
            "   0    8    6    2    4    7    9    3    9    2    8    3    0    1    7    8 \n",
            "   9    1    5    4    9    2    5    7    4    9    9    4    5    9    3    5 \n",
            "   7    0    8    1    9    9    7    8    2    5    3    4    9    0    2    0 \n",
            "   1    9    6    2    1    2    0    7    3    1    1    9    0    5    6    7 \n",
            "\n",
            "Matrix C (A x B):\n",
            " 373  374  376  323  307  351  359  466  334  231  305  289  235  273  340  359 \n",
            " 325  309  368  296  363  390  368  385  322  191  269  245  316  182  317  283 \n",
            " 425  421  454  318  412  465  412  521  369  269  351  323  240  273  364  371 \n",
            " 235  299  291  257  216  288  313  302  287  175  249  241  214  190  228  286 \n",
            " 384  382  365  377  355  442  414  434  361  249  323  270  243  260  297  334 \n",
            " 438  429  454  346  440  469  494  501  349  360  422  340  276  325  312  379 \n",
            " 282  464  408  320  325  422  435  416  350  220  332  327  254  256  327  413 \n",
            " 333  343  283  336  273  415  323  443  299  225  229  186  187  269  287  317 \n",
            " 365  552  490  410  319  488  512  533  433  262  378  367  242  337  415  472 \n",
            " 304  444  396  329  341  428  435  461  327  189  313  320  216  287  327  391 \n",
            " 285  401  359  290  333  354  407  342  323  240  337  286  190  232  275  329 \n",
            " 407  519  495  384  440  529  484  518  399  350  369  352  346  315  371  426 \n",
            " 400  392  392  363  405  461  439  450  350  314  351  269  352  274  309  377 \n",
            " 432  398  412  359  378  407  403  490  333  297  374  306  275  326  369  393 \n",
            " 432  356  374  417  324  467  483  472  427  235  355  265  306  250  317  355 \n",
            " 314  270  380  215  233  325  255  364  239  167  207  217  147  200  262  185 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Addition of two large vectors"
      ],
      "metadata": {
        "id": "qYwYWNLkqKxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_add.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "#define N 1000000  // 1 million elements\n",
        "\n",
        "// CUDA Kernel to perform vector addition\n",
        "__global__ void vectorAdd(int *a, int *b, int *c, int n) {\n",
        "    int idx = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "    if (idx < n) {\n",
        "        c[idx] = a[idx] + b[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Fill array with random integers\n",
        "void fillArray(int *arr, int n) {\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        arr[i] = rand() % 100;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int size = N * sizeof(int);\n",
        "\n",
        "    // Allocate memory on host\n",
        "    int *h_a = (int *)malloc(size);\n",
        "    int *h_b = (int *)malloc(size);\n",
        "    int *h_c = (int *)malloc(size);\n",
        "\n",
        "    // Fill vectors with random data\n",
        "    fillArray(h_a, N);\n",
        "    fillArray(h_b, N);\n",
        "\n",
        "    // Allocate memory on device\n",
        "    int *d_a, *d_b, *d_c;\n",
        "    cudaMalloc((void **)&d_a, size);\n",
        "    cudaMalloc((void **)&d_b, size);\n",
        "    cudaMalloc((void **)&d_c, size);\n",
        "\n",
        "    // Copy vectors to device\n",
        "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch the kernel\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, N);\n",
        "\n",
        "    // Copy result back to host\n",
        "    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print first 10 results for verification\n",
        "    printf(\"Vector Addition Result (first 10 elements):\\n\");\n",
        "    for (int i = 0; i < 10; i++) {\n",
        "        printf(\"%d + %d = %d\\n\", h_a[i], h_b[i], h_c[i]);\n",
        "    }\n",
        "\n",
        "    // Free memory\n",
        "    free(h_a); free(h_b); free(h_c);\n",
        "    cudaFree(d_a); cudaFree(d_b); cudaFree(d_c);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTxlZyJTo54t",
        "outputId": "cbdcd269-453e-491d-ab49-02522171200a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vector_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 vector_add.cu -o vector_add"
      ],
      "metadata": {
        "id": "CcF-b5f0pRxx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./vector_add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rywv8SqbpT5j",
        "outputId": "3914b49c-7de8-4cbb-9d7e-94e7033cabfb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector Addition Result (first 10 elements):\n",
            "83 + 89 = 172\n",
            "86 + 63 = 149\n",
            "77 + 84 = 161\n",
            "15 + 93 = 108\n",
            "93 + 81 = 174\n",
            "35 + 55 = 90\n",
            "86 + 6 = 92\n",
            "92 + 93 = 185\n",
            "49 + 61 = 110\n",
            "21 + 50 = 71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### User Entered Input"
      ],
      "metadata": {
        "id": "U2b6f4BS9RMG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Addition of two large vectors"
      ],
      "metadata": {
        "id": "cwwMk-OG93YT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_add.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "// CUDA Kernel to perform vector addition\n",
        "__global__ void vectorAdd(int *a, int *b, int *c, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n) {\n",
        "        c[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n;\n",
        "    printf(\"Enter the number of elements (up to 1 million): \");\n",
        "    scanf(\"%d\", &n);\n",
        "\n",
        "    if (n <= 0 || n > 1000000) {\n",
        "        printf(\"Invalid input. Please enter a number between 1 and 1000000.\\n\");\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    size_t size = n * sizeof(int);\n",
        "    int *h_a, *h_b, *h_c;\n",
        "    int *d_a, *d_b, *d_c;\n",
        "\n",
        "    // Allocate host memory\n",
        "    h_a = (int *)malloc(size);\n",
        "    h_b = (int *)malloc(size);\n",
        "    h_c = (int *)malloc(size);\n",
        "\n",
        "    // Initialize host arrays with user input\n",
        "    printf(\"Enter %d elements for vector A:\\n\", n);\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        scanf(\"%d\", &h_a[i]);\n",
        "    }\n",
        "\n",
        "    printf(\"Enter %d elements for vector B:\\n\", n);\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        scanf(\"%d\", &h_b[i]);\n",
        "    }\n",
        "\n",
        "    // Allocate device memory\n",
        "    cudaMalloc((void **)&d_a, size);\n",
        "    cudaMalloc((void **)&d_b, size);\n",
        "    cudaMalloc((void **)&d_c, size);\n",
        "\n",
        "    // Copy data from host to device\n",
        "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch the vector addition kernel\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, n);\n",
        "\n",
        "    // Copy the result back to host\n",
        "    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print the first 10 and last 10 results\n",
        "    printf(\"Results (first 10 and last 10):\\n\");\n",
        "    for (int i = 0; i < 10; i++) {\n",
        "        printf(\"%d + %d = %d\\n\", h_a[i], h_b[i], h_c[i]);\n",
        "    }\n",
        "    printf(\"...\\n\");\n",
        "    for (int i = n - 10; i < n; i++) {\n",
        "        printf(\"%d + %d = %d\\n\", h_a[i], h_b[i], h_c[i]);\n",
        "    }\n",
        "\n",
        "    // Free memory\n",
        "    free(h_a); free(h_b); free(h_c);\n",
        "    cudaFree(d_a); cudaFree(d_b); cudaFree(d_c);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "sw3FrVHHpV5D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eae599fb-2396-42cc-9b46-ef7ac978d972"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vector_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 vector_add.cu -o vector_add"
      ],
      "metadata": {
        "id": "cAIgM48D9-CG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./vector_add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVv9XmNI-H-I",
        "outputId": "02660fdb-bb99-41d0-d0e3-b518d3956cb0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the number of elements (up to 1 million): 10\n",
            "Enter 10 elements for vector A:\n",
            "1 2 3 4 5 6 7 8 9 10\n",
            "Enter 10 elements for vector B:\n",
            "10 2 30 40 5 0 70 90 50 100\n",
            "Results (first 10 and last 10):\n",
            "1 + 10 = 11\n",
            "2 + 2 = 4\n",
            "3 + 30 = 33\n",
            "4 + 40 = 44\n",
            "5 + 5 = 10\n",
            "6 + 0 = 6\n",
            "7 + 70 = 77\n",
            "8 + 90 = 98\n",
            "9 + 50 = 59\n",
            "10 + 100 = 110\n",
            "...\n",
            "1 + 10 = 11\n",
            "2 + 2 = 4\n",
            "3 + 30 = 33\n",
            "4 + 40 = 44\n",
            "5 + 5 = 10\n",
            "6 + 0 = 6\n",
            "7 + 70 = 77\n",
            "8 + 90 = 98\n",
            "9 + 50 = 59\n",
            "10 + 100 = 110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_mul.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "// CUDA Kernel for Matrix Multiplication\n",
        "__global__ void matrixMulKernel(int *A, int *B, int *C, int width) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < width && col < width) {\n",
        "        int sum = 0;\n",
        "        for (int k = 0; k < width; k++) {\n",
        "            sum += A[row * width + k] * B[k * width + col];\n",
        "        }\n",
        "        C[row * width + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int width;\n",
        "    printf(\"Enter the matrix size (width x width): \");\n",
        "    scanf(\"%d\", &width);\n",
        "\n",
        "    if (width <= 0 || width > 1024) {\n",
        "        printf(\"Invalid size. Please enter a value between 1 and 1024.\\n\");\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    size_t size = width * width * sizeof(int);\n",
        "    int *h_A, *h_B, *h_C;\n",
        "    int *d_A, *d_B, *d_C;\n",
        "\n",
        "    // Allocate host memory\n",
        "    h_A = (int *)malloc(size);\n",
        "    h_B = (int *)malloc(size);\n",
        "    h_C = (int *)malloc(size);\n",
        "\n",
        "    // Initialize matrices with user input\n",
        "    printf(\"Enter %d x %d elements for matrix A:\\n\", width, width);\n",
        "    for (int i = 0; i < width * width; i++) {\n",
        "        scanf(\"%d\", &h_A[i]);\n",
        "    }\n",
        "\n",
        "    printf(\"Enter %d x %d elements for matrix B:\\n\", width, width);\n",
        "    for (int i = 0; i < width * width; i++) {\n",
        "        scanf(\"%d\", &h_B[i]);\n",
        "    }\n",
        "\n",
        "    // Allocate device memory\n",
        "    cudaMalloc((void **)&d_A, size);\n",
        "    cudaMalloc((void **)&d_B, size);\n",
        "    cudaMalloc((void **)&d_C, size);\n",
        "\n",
        "    // Copy data from host to device\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define block and grid dimensions\n",
        "    dim3 blockDim(16, 16);\n",
        "    dim3 gridDim((width + blockDim.x - 1) / blockDim.x,\n",
        "                 (width + blockDim.y - 1) / blockDim.y);\n",
        "\n",
        "    // Launch kernel\n",
        "    matrixMulKernel<<<gridDim, blockDim>>>(d_A, d_B, d_C, width);\n",
        "\n",
        "    // Copy result back to host\n",
        "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print a portion of the result matrix\n",
        "    printf(\"\\nResult Matrix (first 4x4 and last 4x4 blocks):\\n\");\n",
        "    printf(\"First 4x4 block:\\n\");\n",
        "    for (int i = 0; i < 4 && i < width; i++) {\n",
        "        for (int j = 0; j < 4 && j < width; j++) {\n",
        "            printf(\"%6d \", h_C[i * width + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    if (width > 4) {\n",
        "        printf(\"\\nLast 4x4 block:\\n\");\n",
        "        for (int i = width - 4; i < width; i++) {\n",
        "            for (int j = width - 4; j < width; j++) {\n",
        "                printf(\"%6d \", h_C[i * width + j]);\n",
        "            }\n",
        "            printf(\"\\n\");\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Free memory\n",
        "    free(h_A); free(h_B); free(h_C);\n",
        "    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czXtdKB8-LQm",
        "outputId": "37275c1f-b05e-42cf-9873-497499ce181a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrix_mul.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 matrix_mul.cu -o matrix_mul"
      ],
      "metadata": {
        "id": "QMmpGsTw--34"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./matrix_mul"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OtTBfMN_C6O",
        "outputId": "66f904e1-5b52-4bfe-e5c3-d6570f31edce"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the matrix size (width x width): 2\n",
            "Enter 2 x 2 elements for matrix A:\n",
            "1 2 3 4\n",
            "Enter 2 x 2 elements for matrix B:\n",
            "5 6 7 8\n",
            "\n",
            "Result Matrix (first 4x4 and last 4x4 blocks):\n",
            "First 4x4 block:\n",
            "    19     22 \n",
            "    43     50 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "2"
      ],
      "metadata": {
        "id": "aNzyfPyf_F8a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}