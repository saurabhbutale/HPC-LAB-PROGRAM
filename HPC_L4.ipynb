{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Basic Command for accessing the CUDA Version and GPU Information\n",
        "####Runtime > Change runtime type > Setting the Hardware accelerator to GPU > Save"
      ],
      "metadata": {
        "id": "-ycIIE8spfuT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ7HeLnRkijK",
        "outputId": "d8baee37-b5a4-425b-b1a0-d19a042401fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin    cuda\tcuda-12.5\t  etc\t include  libexec     man  sbin   src\n",
            "colab  cuda-12\tdist_metrics.pxd  games  lib\t  LICENSE.md  opt  share\n"
          ]
        }
      ],
      "source": [
        "!ls /usr/local/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!which nvcc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFuDJT66k0oU",
        "outputId": "7ee1d47f-26dc-4557-bc5d-615ac571c39f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/cuda/bin/nvcc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFDkjJjtlBvm",
        "outputId": "55ffc69a-a53e-4302-b32b-fbc746659dde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Apr 10 12:15:00 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### Matrix Multiplication using CUDA C"
      ],
      "metadata": {
        "id": "vXkkfMmdqF0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_mul.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "#define N 16  // You can increase this to 512 or 1024 for bigger matrices\n",
        "\n",
        "// CUDA Kernel for Matrix Multiplication\n",
        "__global__ void matrixMulKernel(int *A, int *B, int *C, int width) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < width && col < width) {\n",
        "        int sum = 0;\n",
        "        for (int k = 0; k < width; k++) {\n",
        "            sum += A[row * width + k] * B[k * width + col];\n",
        "        }\n",
        "        C[row * width + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "void fillMatrix(int *mat, int width) {\n",
        "    for (int i = 0; i < width * width; i++) {\n",
        "        mat[i] = rand() % 10; // fill with random values 0-9\n",
        "    }\n",
        "}\n",
        "\n",
        "void printMatrix(int *mat, int width) {\n",
        "    for (int i = 0; i < width; i++) {\n",
        "        for (int j = 0; j < width; j++) {\n",
        "            printf(\"%4d \", mat[i * width + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int size = N * N * sizeof(int);\n",
        "\n",
        "    // Allocate memory on host\n",
        "    int *h_A = (int *)malloc(size);\n",
        "    int *h_B = (int *)malloc(size);\n",
        "    int *h_C = (int *)malloc(size);\n",
        "\n",
        "    // Fill host matrices with random values\n",
        "    fillMatrix(h_A, N);\n",
        "    fillMatrix(h_B, N);\n",
        "\n",
        "    // Allocate memory on device\n",
        "    int *d_A, *d_B, *d_C;\n",
        "    cudaMalloc((void **)&d_A, size);\n",
        "    cudaMalloc((void **)&d_B, size);\n",
        "    cudaMalloc((void **)&d_C, size);\n",
        "\n",
        "    // Copy host matrices to device\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define grid and block dimensions\n",
        "    dim3 dimBlock(16, 16);\n",
        "    dim3 dimGrid((N + dimBlock.x - 1) / dimBlock.x,\n",
        "                 (N + dimBlock.y - 1) / dimBlock.y);\n",
        "\n",
        "    // Launch CUDA kernel\n",
        "    matrixMulKernel<<<dimGrid, dimBlock>>>(d_A, d_B, d_C, N);\n",
        "\n",
        "    // Copy result back to host\n",
        "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print results\n",
        "    printf(\"Matrix A:\\n\");\n",
        "    printMatrix(h_A, N);\n",
        "    printf(\"\\nMatrix B:\\n\");\n",
        "    printMatrix(h_B, N);\n",
        "    printf(\"\\nMatrix C (A x B):\\n\");\n",
        "    printMatrix(h_C, N);\n",
        "\n",
        "    // Free memory\n",
        "    free(h_A); free(h_B); free(h_C);\n",
        "    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "032hGQ_sljMD",
        "outputId": "68e98bad-0b5e-43f8-affc-99ea10b8e87c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_mul.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 matrix_mul.cu -o matrix_mul"
      ],
      "metadata": {
        "id": "9cBOnKU4o1ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./matrix_mul"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3IfR2Boo3xw",
        "outputId": "6e61cd57-d295-4db2-92a3-81ed5f99f2ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix A:\n",
            "   3    6    7    5    3    5    6    2    9    1    2    7    0    9    3    6 \n",
            "   0    6    2    6    1    8    7    9    2    0    2    3    7    5    9    2 \n",
            "   2    8    9    7    3    6    1    2    9    3    1    9    4    7    8    4 \n",
            "   5    0    3    6    1    0    6    3    2    0    6    1    5    5    4    7 \n",
            "   6    5    6    9    3    7    4    5    2    5    4    7    4    4    3    0 \n",
            "   7    8    6    8    8    4    3    1    4    9    2    0    6    8    9    2 \n",
            "   6    6    4    9    5    0    4    8    7    1    7    2    7    2    2    6 \n",
            "   1    0    6    1    5    9    4    9    0    9    1    7    7    1    1    5 \n",
            "   9    7    7    6    7    3    6    5    6    3    9    4    8    1    2    9 \n",
            "   3    9    0    8    8    5    0    9    6    3    8    5    6    1    1    5 \n",
            "   9    8    4    8    1    0    3    0    4    4    4    4    7    6    3    1 \n",
            "   7    5    9    6    2    1    7    8    5    7    4    1    8    5    9    7 \n",
            "   5    3    8    8    3    1    8    9    6    4    3    3    3    8    6    0 \n",
            "   4    8    8    8    9    7    7    6    4    3    0    3    0    9    2    5 \n",
            "   4    0    5    9    4    6    9    2    2    4    7    7    5    4    8    1 \n",
            "   2    8    9    3    6    8    0    2    1    0    5    1    1    0    8    5 \n",
            "\n",
            "Matrix B:\n",
            "   0    6    4    6    2    5    8    6    2    8    4    7    2    4    0    6 \n",
            "   2    9    9    0    8    1    3    1    1    0    3    4    0    3    9    1 \n",
            "   9    6    9    3    3    8    0    5    6    6    4    0    0    4    6    2 \n",
            "   6    7    5    6    9    8    7    2    8    2    9    9    6    0    2    7 \n",
            "   6    1    3    2    1    5    9    9    1    4    9    1    0    7    5    8 \n",
            "   7    0    4    8    0    4    2    9    6    1    0    4    2    2    2    0 \n",
            "   5    5    2    9    0    2    8    3    8    0    4    0    9    1    9    6 \n",
            "   2    5    4    4    9    9    3    6    0    5    0    2    9    4    3    5 \n",
            "   1    7    4    3    1    4    6    9    4    2    2    6    4    1    2    8 \n",
            "   8    9    2    8    8    8    6    8    3    8    3    3    3    8    0    4 \n",
            "   7    6    8    9    0    6    8    7    9    0    3    3    3    7    3    2 \n",
            "   6    5    2    6    5    8    7    9    6    0    4    1    0    4    8    7 \n",
            "   0    8    6    2    4    7    9    3    9    2    8    3    0    1    7    8 \n",
            "   9    1    5    4    9    2    5    7    4    9    9    4    5    9    3    5 \n",
            "   7    0    8    1    9    9    7    8    2    5    3    4    9    0    2    0 \n",
            "   1    9    6    2    1    2    0    7    3    1    1    9    0    5    6    7 \n",
            "\n",
            "Matrix C (A x B):\n",
            " 373  374  376  323  307  351  359  466  334  231  305  289  235  273  340  359 \n",
            " 325  309  368  296  363  390  368  385  322  191  269  245  316  182  317  283 \n",
            " 425  421  454  318  412  465  412  521  369  269  351  323  240  273  364  371 \n",
            " 235  299  291  257  216  288  313  302  287  175  249  241  214  190  228  286 \n",
            " 384  382  365  377  355  442  414  434  361  249  323  270  243  260  297  334 \n",
            " 438  429  454  346  440  469  494  501  349  360  422  340  276  325  312  379 \n",
            " 282  464  408  320  325  422  435  416  350  220  332  327  254  256  327  413 \n",
            " 333  343  283  336  273  415  323  443  299  225  229  186  187  269  287  317 \n",
            " 365  552  490  410  319  488  512  533  433  262  378  367  242  337  415  472 \n",
            " 304  444  396  329  341  428  435  461  327  189  313  320  216  287  327  391 \n",
            " 285  401  359  290  333  354  407  342  323  240  337  286  190  232  275  329 \n",
            " 407  519  495  384  440  529  484  518  399  350  369  352  346  315  371  426 \n",
            " 400  392  392  363  405  461  439  450  350  314  351  269  352  274  309  377 \n",
            " 432  398  412  359  378  407  403  490  333  297  374  306  275  326  369  393 \n",
            " 432  356  374  417  324  467  483  472  427  235  355  265  306  250  317  355 \n",
            " 314  270  380  215  233  325  255  364  239  167  207  217  147  200  262  185 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Addition of two large vectors"
      ],
      "metadata": {
        "id": "qYwYWNLkqKxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_add.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "#define N 1000000  // 1 million elements\n",
        "\n",
        "// CUDA Kernel to perform vector addition\n",
        "__global__ void vectorAdd(int *a, int *b, int *c, int n) {\n",
        "    int idx = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "    if (idx < n) {\n",
        "        c[idx] = a[idx] + b[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Fill array with random integers\n",
        "void fillArray(int *arr, int n) {\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        arr[i] = rand() % 100;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int size = N * sizeof(int);\n",
        "\n",
        "    // Allocate memory on host\n",
        "    int *h_a = (int *)malloc(size);\n",
        "    int *h_b = (int *)malloc(size);\n",
        "    int *h_c = (int *)malloc(size);\n",
        "\n",
        "    // Fill vectors with random data\n",
        "    fillArray(h_a, N);\n",
        "    fillArray(h_b, N);\n",
        "\n",
        "    // Allocate memory on device\n",
        "    int *d_a, *d_b, *d_c;\n",
        "    cudaMalloc((void **)&d_a, size);\n",
        "    cudaMalloc((void **)&d_b, size);\n",
        "    cudaMalloc((void **)&d_c, size);\n",
        "\n",
        "    // Copy vectors to device\n",
        "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch the kernel\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, N);\n",
        "\n",
        "    // Copy result back to host\n",
        "    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print first 10 results for verification\n",
        "    printf(\"Vector Addition Result (first 10 elements):\\n\");\n",
        "    for (int i = 0; i < 10; i++) {\n",
        "        printf(\"%d + %d = %d\\n\", h_a[i], h_b[i], h_c[i]);\n",
        "    }\n",
        "\n",
        "    // Free memory\n",
        "    free(h_a); free(h_b); free(h_c);\n",
        "    cudaFree(d_a); cudaFree(d_b); cudaFree(d_c);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTxlZyJTo54t",
        "outputId": "06508653-58c5-496f-d469-c97eb6603dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vector_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 vector_add.cu -o vector_add"
      ],
      "metadata": {
        "id": "CcF-b5f0pRxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./vector_add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rywv8SqbpT5j",
        "outputId": "5037a5c2-0f13-49f5-d351-3885ef107bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector Addition Result (first 10 elements):\n",
            "83 + 89 = 172\n",
            "86 + 63 = 149\n",
            "77 + 84 = 161\n",
            "15 + 93 = 108\n",
            "93 + 81 = 174\n",
            "35 + 55 = 90\n",
            "86 + 6 = 92\n",
            "92 + 93 = 185\n",
            "49 + 61 = 110\n",
            "21 + 50 = 71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sw3FrVHHpV5D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}